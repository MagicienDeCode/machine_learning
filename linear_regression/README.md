# Linear regression

- 线性回归（Linear Regression）是一种统计方法，用于分析两个或多个变量之间的关系，特别是用于预测和解释因变量（响应变量）与一个或多个自变量（预测变量）之间的线性关系。其主要目的是建立一个数学模型，通过已知的自变量来预测因变量的值。

## When

- 预测股票价格。
- 分析市场趋势。
- 研究某种药物对疾病的影响。

## R-Squared
- R-Squared（R²）是一种常用的统计指标，用于评估线性回归模型的拟合优度。它表示自变量解释因变量变异的比例。R²的值介于0和1之间，值越接近1，模型的拟合效果越好。
- **对于多元回归，调整 R²（Adjusted R-Squared） 是更好的选择，因为它考虑了模型中自变量的数量。**

## RMSE
- 均方根误差（Root Mean Squared Error, RMSE）是一种常用的回归模型评估指标，用于衡量预测值与实际值之间的差异。RMSE提供了预测误差的平方根，反映了模型预测的标准差。它的值越小，模型的预测性能越好。

## Feature Importance
- 绘制每个特征的重要性是分析模型的一个重要部分。在线性回归中，特征的重要性通常可以通过查看模型的系数（回归系数）来确定。回归系数表示了每个特征对目标变量的影响大小。